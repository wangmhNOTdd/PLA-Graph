#!/usr/bin/env python3
"""
æµ‹è¯•ä¼˜åŒ–ç‰ˆDSANæ¨¡å‹çš„æ­£ç¡®æ€§å’Œæ€§èƒ½
"""

import torch
import torch.nn as nn
import time
import numpy as np
from models.DSAN.encoder import DSANEncoder
from models.DSAN.optimized_encoder import OptimizedDSANEncoder

def generate_test_data(n_atoms=100, n_blocks=10, hidden_size=128, device='cuda'):
    """ç”Ÿæˆæµ‹è¯•æ•°æ®"""
    
    # åŸå­ç‰¹å¾
    H = torch.randn(n_atoms, hidden_size, device=device)
    
    # åŸå­åæ ‡
    Z = torch.randn(n_atoms, 1, 3, device=device)
    
    # å—ID (æ¯ä¸ªå—å¹³å‡åŒ…å«n_atoms/n_blocksä¸ªåŸå­)
    block_id = torch.repeat_interleave(torch.arange(n_blocks, device=device), 
                                      n_atoms // n_blocks)
    if len(block_id) < n_atoms:
        # å¤„ç†ä¸èƒ½æ•´é™¤çš„æƒ…å†µ
        remainder = n_atoms - len(block_id)
        block_id = torch.cat([block_id, torch.full((remainder,), n_blocks-1, device=device)])
    
    # æ‰¹æ¬¡ID
    batch_id = torch.zeros(n_blocks, dtype=torch.long, device=device)
    
    # å—é—´è¾¹ï¼ˆéšæœºç”Ÿæˆä¸€äº›è¾¹ï¼‰
    n_edges = min(50, n_blocks * (n_blocks - 1) // 4)  # é™åˆ¶è¾¹æ•°
    src_blocks = torch.randint(0, n_blocks, (n_edges,), device=device)
    dst_blocks = torch.randint(0, n_blocks, (n_edges,), device=device)
    # ç¡®ä¿ä¸æ˜¯è‡ªç¯
    mask = src_blocks != dst_blocks
    edges = torch.stack([src_blocks[mask], dst_blocks[mask]])
    
    return H, Z, block_id, batch_id, edges

def benchmark_model(model, H, Z, block_id, batch_id, edges, n_runs=10):
    """æµ‹è¯•æ¨¡å‹æ€§èƒ½"""
    model.eval()
    
    # é¢„çƒ­
    with torch.no_grad():
        _ = model(H, Z, block_id, batch_id, edges)
    
    # è®¡æ—¶
    torch.cuda.synchronize()
    start_time = time.time()
    
    with torch.no_grad():
        for _ in range(n_runs):
            _ = model(H, Z, block_id, batch_id, edges)
    
    torch.cuda.synchronize()
    end_time = time.time()
    
    avg_time = (end_time - start_time) / n_runs
    return avg_time

def test_correctness(original_model, optimized_model, H, Z, block_id, batch_id, edges, tolerance=1e-4):
    """æµ‹è¯•ä¸¤ä¸ªæ¨¡å‹è¾“å‡ºçš„ä¸€è‡´æ€§"""
    original_model.eval()
    optimized_model.eval()
    
    with torch.no_grad():
        # åŸå§‹æ¨¡å‹è¾“å‡º
        orig_atom, orig_block, orig_graph, orig_pred_z = original_model(H, Z, block_id, batch_id, edges)
        
        # ä¼˜åŒ–æ¨¡å‹è¾“å‡º
        opt_atom, opt_block, opt_graph, opt_pred_z = optimized_model(H, Z, block_id, batch_id, edges)
        
        # æ¯”è¾ƒåŸå­ç‰¹å¾
        atom_diff = torch.abs(orig_atom - opt_atom).max().item()
        
        # æ¯”è¾ƒå—ç‰¹å¾
        block_diff = torch.abs(orig_block - opt_block).max().item()
        
        # æ¯”è¾ƒå›¾ç‰¹å¾
        graph_diff = torch.abs(orig_graph - opt_graph).max().item()
        
        print(f"åŸå­ç‰¹å¾æœ€å¤§å·®å¼‚: {atom_diff:.6f}")
        print(f"å—ç‰¹å¾æœ€å¤§å·®å¼‚: {block_diff:.6f}")
        print(f"å›¾ç‰¹å¾æœ€å¤§å·®å¼‚: {graph_diff:.6f}")
        
        # æ£€æŸ¥æ˜¯å¦åœ¨å®¹å¿èŒƒå›´å†…
        is_correct = (atom_diff < tolerance and 
                     block_diff < tolerance and 
                     graph_diff < tolerance)
        
        return is_correct, atom_diff, block_diff, graph_diff

def main():
    print("ğŸ”§ æµ‹è¯•ä¼˜åŒ–ç‰ˆDSANæ¨¡å‹...")
    print("=" * 50)
    
    # æ£€æŸ¥CUDA
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    if device == 'cuda':
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    print("=" * 50)
    
    # æ¨¡å‹å‚æ•°
    hidden_size = 128
    n_layers = 3
    num_heads = 8
    k_neighbors = 9
    dropout = 0.1
    rbf_dim = 16
    cutoff = 10.0
    
    print("åˆ›å»ºæ¨¡å‹...")
    
    # åˆ›å»ºåŸå§‹DSANæ¨¡å‹
    original_model = DSANEncoder(
        hidden_size=hidden_size,
        n_layers=n_layers,
        num_heads=num_heads,
        k_neighbors=k_neighbors,
        dropout=dropout,
        use_geometry=True,
        rbf_dim=rbf_dim,
        cutoff=cutoff
    ).to(device)
    
    # åˆ›å»ºä¼˜åŒ–ç‰ˆDSANæ¨¡å‹
    optimized_model = OptimizedDSANEncoder(
        hidden_size=hidden_size,
        n_layers=n_layers,
        num_heads=num_heads,
        k_neighbors=k_neighbors,
        dropout=dropout,
        use_geometry=True,
        rbf_dim=rbf_dim,
        cutoff=cutoff
    ).to(device)
    
    print(f"åŸå§‹æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in original_model.parameters()):,}")
    print(f"ä¼˜åŒ–æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in optimized_model.parameters()):,}")
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    print("\nç”Ÿæˆæµ‹è¯•æ•°æ®...")
    test_sizes = [
        (50, 5),    # å°è§„æ¨¡
        (100, 10),  # ä¸­è§„æ¨¡
        (200, 20),  # å¤§è§„æ¨¡
    ]
    
    for n_atoms, n_blocks in test_sizes:
        print(f"\næµ‹è¯•è§„æ¨¡: {n_atoms} åŸå­, {n_blocks} å—")
        print("-" * 30)
        
        H, Z, block_id, batch_id, edges = generate_test_data(
            n_atoms=n_atoms, 
            n_blocks=n_blocks, 
            hidden_size=hidden_size, 
            device=device
        )
        
        print(f"æ•°æ®å½¢çŠ¶:")
        print(f"  åŸå­ç‰¹å¾: {H.shape}")
        print(f"  åæ ‡: {Z.shape}")
        print(f"  å—ID: {block_id.shape}")
        print(f"  è¾¹æ•°: {edges.shape[1]}")
        
        # æµ‹è¯•æ­£ç¡®æ€§
        print("\næµ‹è¯•è¾“å‡ºä¸€è‡´æ€§...")
        try:
            is_correct, atom_diff, block_diff, graph_diff = test_correctness(
                original_model, optimized_model, H, Z, block_id, batch_id, edges
            )
            
            if is_correct:
                print("âœ… è¾“å‡ºä¸€è‡´æ€§æµ‹è¯•é€šè¿‡!")
            else:
                print("âŒ è¾“å‡ºä¸€è‡´æ€§æµ‹è¯•å¤±è´¥!")
                print(f"   æœ€å¤§å·®å¼‚: åŸå­={atom_diff:.6f}, å—={block_diff:.6f}, å›¾={graph_diff:.6f}")
                
        except Exception as e:
            print(f"âŒ æ­£ç¡®æ€§æµ‹è¯•å‡ºé”™: {e}")
            continue
        
        # æ€§èƒ½æµ‹è¯•
        print("\næ€§èƒ½æµ‹è¯•...")
        try:
            orig_time = benchmark_model(original_model, H, Z, block_id, batch_id, edges, n_runs=5)
            opt_time = benchmark_model(optimized_model, H, Z, block_id, batch_id, edges, n_runs=5)
            
            speedup = orig_time / opt_time
            
            print(f"åŸå§‹æ¨¡å‹å¹³å‡æ—¶é—´: {orig_time*1000:.2f} ms")
            print(f"ä¼˜åŒ–æ¨¡å‹å¹³å‡æ—¶é—´: {opt_time*1000:.2f} ms") 
            print(f"åŠ é€Ÿæ¯”: {speedup:.2f}x")
            
            if speedup > 1.0:
                print("âœ… æ€§èƒ½ä¼˜åŒ–æˆåŠŸ!")
            else:
                print("âš ï¸  æ€§èƒ½å¯èƒ½æ²¡æœ‰æå‡")
                
        except Exception as e:
            print(f"âŒ æ€§èƒ½æµ‹è¯•å‡ºé”™: {e}")
    
    print("\n" + "=" * 50)
    print("æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main()
