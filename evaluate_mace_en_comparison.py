#!/usr/bin/env python3
"""
è¯„ä¼°MACE-Enæ¨¡å‹å¹¶å¯¹æ¯”åŸMACEæ€§èƒ½
"""

import subprocess
import sys
import os
import json

def evaluate_model(model_name, ckpt_path, save_prefix):
    """è¯„ä¼°å•ä¸ªæ¨¡å‹"""
    
    print(f"\nğŸ” è¯„ä¼° {model_name}...")
    
    # åˆ›å»ºç»“æœç›®å½•
    results_dir = f"./results/{save_prefix}"
    os.makedirs(results_dir, exist_ok=True)
    
    # éªŒè¯é›†æ¨æ–­
    print("ğŸ“Š éªŒè¯é›†æ¨æ–­...")
    cmd_valid = [
        sys.executable, "inference.py",
        "--test_set", "./datasets/PDBBind/processed/identity30/valid.pkl",
        "--ckpt", ckpt_path,
        "--task", "PDBBind",
        "--save_path", f"{results_dir}/valid_predictions.jsonl",
        "--gpu", "0"
    ]
    subprocess.run(cmd_valid, check=True)
    
    # æµ‹è¯•é›†æ¨æ–­
    print("ğŸ“Š æµ‹è¯•é›†æ¨æ–­...")
    cmd_test = [
        sys.executable, "inference.py",
        "--test_set", "./datasets/PDBBind/processed/identity30/test.pkl",
        "--ckpt", ckpt_path,
        "--task", "PDBBind",
        "--save_path", f"{results_dir}/test_predictions.jsonl",
        "--gpu", "0"
    ]
    subprocess.run(cmd_test, check=True)
    
    # è¯„ä¼°æ€§èƒ½
    print(f"ğŸ“ˆ {model_name} - éªŒè¯é›†æ€§èƒ½:")
    cmd_eval_valid = [
        sys.executable, "evaluate.py",
        "--predictions", f"{results_dir}/valid_predictions.jsonl"
    ]
    subprocess.run(cmd_eval_valid, check=True)
    
    print(f"ğŸ“ˆ {model_name} - æµ‹è¯•é›†æ€§èƒ½:")
    cmd_eval_test = [
        sys.executable, "evaluate.py",
        "--predictions", f"{results_dir}/test_predictions.jsonl"
    ]
    subprocess.run(cmd_eval_test, check=True)

def main():
    print("ğŸš€ MACE-En vs åŸMACE æ€§èƒ½å¯¹æ¯”è¯„ä¼°...")
    print("=" * 60)
    
    # æ£€æŸ¥å¯ç”¨çš„æ¨¡å‹æ£€æŸ¥ç‚¹
    models_to_evaluate = []
    
    # MACE-En Enhanced
    mace_en_dir = "./datasets/PDBBind/processed/identity30/models/MACE_En_standard"
    if os.path.exists(mace_en_dir):
        # æŸ¥æ‰¾æœ€ä½³æ£€æŸ¥ç‚¹
        ckpt_dir = os.path.join(mace_en_dir, "version_0/checkpoint")
        if os.path.exists(ckpt_dir):
            topk_file = os.path.join(ckpt_dir, "topk_map.txt")
            if os.path.exists(topk_file):
                with open(topk_file, 'r') as f:
                    best_line = f.readline().strip()
                    best_ckpt = best_line.split(': ')[1]
                    models_to_evaluate.append({
                        "name": "MACE-En Enhanced",
                        "ckpt": best_ckpt,
                        "prefix": "mace_en_enhanced"
                    })
    
    # åŸMACE Gaussian V1 (ä¹‹å‰æœ€ä½³)
    mace_orig_dir = "./datasets/PDBBind/processed/identity30/models/MACE_gaussian/version_1/checkpoint"
    if os.path.exists(mace_orig_dir):
        best_ckpt = os.path.join(mace_orig_dir, "epoch5_step4560.ckpt")
        if os.path.exists(best_ckpt):
            models_to_evaluate.append({
                "name": "MACE Original V1",
                "ckpt": best_ckpt,
                "prefix": "mace_original_v1"
            })
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ¨¡å‹å¯è¯„ä¼°
    if not models_to_evaluate:
        print("âŒ æœªæ‰¾åˆ°å¯è¯„ä¼°çš„æ¨¡å‹æ£€æŸ¥ç‚¹ï¼")
        print("è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ç”Ÿæˆæ¨¡å‹ã€‚")
        return 1
    
    # è¯„ä¼°æ‰€æœ‰æ¨¡å‹
    print(f"ğŸ“‹ å‘ç° {len(models_to_evaluate)} ä¸ªæ¨¡å‹å¾…è¯„ä¼°:")
    for model in models_to_evaluate:
        print(f"   - {model['name']}")
    
    try:
        for model in models_to_evaluate:
            evaluate_model(model["name"], model["ckpt"], model["prefix"])
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰æ¨¡å‹è¯„ä¼°å®Œæˆ!")
        print("\nğŸ“Š ç»“æœå¯¹æ¯”:")
        print("   æ£€æŸ¥å„æ¨¡å‹åœ¨éªŒè¯é›†å’Œæµ‹è¯•é›†ä¸Šçš„æ€§èƒ½")
        print("   é‡ç‚¹å…³æ³¨æ•°å€¼ç¨³å®šæ€§å’Œé¢„æµ‹ç²¾åº¦çš„æ”¹è¿›")
        print("\nğŸ“ ç»“æœä¿å­˜åœ¨ ./results/ ç›®å½•ä¸‹")
        print("=" * 60)
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
