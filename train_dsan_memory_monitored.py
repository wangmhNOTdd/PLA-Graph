#!/usr/bin/env python3
"""
DSANæ˜¾å­˜ç›‘æ§è®­ç»ƒè„šæœ¬
å®æ—¶ç›‘æ§GPUæ˜¾å­˜ä½¿ç”¨ï¼Œé˜²æ­¢çˆ†æ˜¾å­˜
"""

import subprocess
import sys
import os
import time
import threading
import torch
import psutil

class MemoryMonitor:
    def __init__(self, check_interval=5, warning_threshold=20.0):
        self.check_interval = check_interval
        self.warning_threshold = warning_threshold  # GB
        self.running = False
        self.max_gpu_memory = 0.0
        self.max_cpu_memory = 0.0
        self.warning_count = 0
        
    def start_monitoring(self):
        self.running = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
        print("ğŸ” æ˜¾å­˜ç›‘æ§å·²å¯åŠ¨...")
        
    def stop_monitoring(self):
        self.running = False
        if hasattr(self, 'monitor_thread'):
            self.monitor_thread.join(timeout=2)
            
    def _monitor_loop(self):
        while self.running:
            try:
                if torch.cuda.is_available():
                    # GPUæ˜¾å­˜ç›‘æ§
                    gpu_allocated = torch.cuda.memory_allocated() / 1024**3  # GB
                    gpu_reserved = torch.cuda.memory_reserved() / 1024**3   # GB
                    gpu_free = (torch.cuda.get_device_properties(0).total_memory / 1024**3) - gpu_reserved
                    
                    # CPUå†…å­˜ç›‘æ§
                    cpu_memory = psutil.virtual_memory().used / 1024**3   # GB
                    cpu_percent = psutil.virtual_memory().percent
                    
                    # æ›´æ–°æœ€å¤§ä½¿ç”¨é‡
                    if gpu_allocated > self.max_gpu_memory:
                        self.max_gpu_memory = gpu_allocated
                    if cpu_memory > self.max_cpu_memory:
                        self.max_cpu_memory = cpu_memory
                    
                    # æ˜¾ç¤ºå½“å‰çŠ¶æ€
                    status_msg = (f"[Memory] GPU: {gpu_allocated:.1f}GB ({gpu_reserved:.1f}GB reserved, "
                                f"{gpu_free:.1f}GB free) | CPU: {cpu_memory:.1f}GB ({cpu_percent:.1f}%) | "
                                f"Max GPU: {self.max_gpu_memory:.1f}GB")
                    print(status_msg)
                    
                    # æ˜¾å­˜è­¦å‘Šå’Œæ¸…ç†
                    if gpu_allocated > self.warning_threshold:
                        self.warning_count += 1
                        print(f"âš ï¸  æ˜¾å­˜ä½¿ç”¨è¿‡é«˜! ({gpu_allocated:.1f}GB > {self.warning_threshold}GB) "
                              f"è­¦å‘Šæ¬¡æ•°: {self.warning_count}")
                        
                        # å¼ºåˆ¶æ¸…ç†æ˜¾å­˜
                        torch.cuda.empty_cache()
                        print("ğŸ§¹ å·²æ‰§è¡Œæ˜¾å­˜æ¸…ç†")
                        
                        # å¦‚æœè¿ç»­å¤šæ¬¡è­¦å‘Šï¼Œé™ä½ç›‘æ§é¢‘ç‡é¿å…æ—¥å¿—åˆ·å±
                        if self.warning_count > 5:
                            time.sleep(self.check_interval * 2)
                            continue
                    
                    # ä¸´ç•Œå€¼æ£€æŸ¥ï¼ˆ7GBï¼Œæ¥è¿‘4060çš„8GBæé™ï¼‰
                    if gpu_allocated > 7.0:
                        print("ğŸš¨ æ˜¾å­˜ä¸¥é‡ä¸è¶³! å¯èƒ½å³å°†OOM!")
                        print("å»ºè®®ç«‹å³æ£€æŸ¥æ¨¡å‹å‚æ•°æˆ–å‡å°batch_size")
                        
                else:
                    print("[Memory] CUDAä¸å¯ç”¨ï¼Œæ— æ³•ç›‘æ§GPUæ˜¾å­˜")
                    
            except Exception as e:
                print(f"âš ï¸  æ˜¾å­˜ç›‘æ§å‡ºé”™: {e}")
                
            time.sleep(self.check_interval)
    
    def get_summary(self):
        return (f"\næ˜¾å­˜ç›‘æ§æ€»ç»“:\n"
                f"æœ€å¤§GPUæ˜¾å­˜ä½¿ç”¨: {self.max_gpu_memory:.2f} GB\n"
                f"æœ€å¤§CPUå†…å­˜ä½¿ç”¨: {self.max_cpu_memory:.2f} GB\n"
                f"æ˜¾å­˜è­¦å‘Šæ¬¡æ•°: {self.warning_count}")

def main():
    print("ğŸš€ å¯åŠ¨DSANæ¨¡å‹è®­ç»ƒï¼ˆå¸¦æ˜¾å­˜ç›‘æ§ï¼‰...")
    print("=" * 60)
    
    # æ£€æŸ¥GPUçŠ¶æ€
    print("GPUçŠ¶æ€æ£€æŸ¥:")
    if torch.cuda.is_available():
        print(f"   CUDAå¯ç”¨: âœ…")
        print(f"   GPUæ•°é‡: {torch.cuda.device_count()}")
        print(f"   GPUåç§°: {torch.cuda.get_device_name(0)}")
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"   æ˜¾å­˜å¤§å°: {gpu_memory:.1f} GB")
        print(f"   å½“å‰æ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated() / 1024**3:.2f} GB")
    else:
        print("   CUDAå¯ç”¨: âŒ")
        return 1
    
    print("=" * 60)
    
    # å¯åŠ¨æ˜¾å­˜ç›‘æ§ (RTX 4060: 8GBæ˜¾å­˜)
    monitor = MemoryMonitor(check_interval=8, warning_threshold=6.0)  # 4060è®¾ç½®ä¸º6GBè­¦å‘Š
    monitor.start_monitoring()
    
    try:
        # æ„å»ºä¼˜åŒ–çš„è®­ç»ƒå‘½ä»¤
        cmd = [
            sys.executable, "train.py",
            "--train_set", "./datasets/PDBBind/processed/identity30/train.pkl",
            "--valid_set", "./datasets/PDBBind/processed/identity30/valid.pkl", 
            "--save_dir", "./datasets/PDBBind/processed/identity30/models/DSAN_memory_optimized",
            "--task", "PDBBind",
            "--lr", "0.001",
            "--final_lr", "0.0001", 
            "--max_epoch", "100",
            "--save_topk", "5",
            "--batch_size", "1",  # 4060æ˜¾å­˜è¾ƒå°ï¼Œä½¿ç”¨æœ€å°æ‰¹æ¬¡
            "--valid_batch_size", "1",
            "--grad_clip", "1.0",
            "--warmup", "1000",
            "--shuffle",
            "--model_type", "DSAN",
            "--hidden_size", "64",   # å‡å°‘éšè—å±‚å¤§å°
            "--n_layers", "2",       # å‡å°‘å±‚æ•°
            "--n_channel", "1", 
            "--n_rbf", "8",          # å¤§å¹…å‡å°‘RBFç»´åº¦
            "--cutoff", "6.0",       # å¤§å¹…å‡å°‘cutoff
            "--n_head", "4",         # å‡å°‘æ³¨æ„åŠ›å¤´æ•°
            "--radial_size", "4",    # å¤§å¹…å‡å°‘å‡ ä½•ç‰¹å¾ç»´åº¦
            "--k_neighbors", "4",    # å¤§å¹…å‡å°‘Kè¿‘é‚»æ•°
            "--seed", "2024",
            "--gpus", "0"
        ]
        
        print("è®­ç»ƒé…ç½®ï¼ˆ4060æ˜¾å­˜ä¼˜åŒ–ï¼‰:")
        print(f"   æ‰¹æ¬¡å¤§å°: 1 (4060ä¿å®ˆè®¾ç½®)")
        print(f"   RBFç»´åº¦: 8 (å¤§å¹…å‡å°‘)")
        print(f"   Cutoff: 6.0 (å¤§å¹…å‡å°‘è¾¹æ•°é‡)")
        print(f"   å‡ ä½•ç‰¹å¾ç»´åº¦: 4 (å¤§å¹…å‡å°‘)")
        print(f"   Kè¿‘é‚»æ•°: 4 (å¤§å¹…å‡å°‘)")
        print(f"   éšè—å±‚å¤§å°: 64 (å‡å°‘å‚æ•°é‡)")
        print(f"   æ˜¾å­˜è­¦å‘Šé˜ˆå€¼: 6GB")
        print("=" * 60)
        
        # æ‰§è¡Œè®­ç»ƒ
        print("ğŸ¯ å¼€å§‹è®­ç»ƒ... (Ctrl+C ä¸­æ–­)")
        start_time = time.time()
        
        result = subprocess.run(cmd, check=True)
        
        end_time = time.time()
        training_time = (end_time - start_time) / 3600  # hours
        
        print("âœ… è®­ç»ƒå®Œæˆ!")
        print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: ./datasets/PDBBind/processed/identity30/models/DSAN_memory_optimized")
        print(f"è®­ç»ƒç”¨æ—¶: {training_time:.2f} å°æ—¶")
        
        return 0
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        return 1
    except KeyboardInterrupt:
        print("â›” è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
        return 1
    finally:
        # åœæ­¢ç›‘æ§å¹¶æ˜¾ç¤ºæ‘˜è¦
        monitor.stop_monitoring()
        print(monitor.get_summary())
        print("=" * 60)
        print("è®­ç»ƒç»“æŸ")

if __name__ == "__main__":
    exit(main())
