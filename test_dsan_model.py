#!/usr/bin/env python3
"""
DSANæ¨¡å‹æµ‹è¯•è„šæœ¬ - éªŒè¯æ¨¡å‹åˆå§‹åŒ–å’Œå‰å‘ä¼ æ’­
"""

import torch
import torch.nn as nn
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')

from models.DSAN.encoder import DSANEncoder, DSANLayer
from models import create_model
from utils.nn_utils import count_parameters

def test_dsan_encoder():
    """æµ‹è¯•DSANç¼–ç å™¨åŸºæœ¬åŠŸèƒ½"""
    print("=" * 60)
    print("ğŸ§ª æµ‹è¯•DSANç¼–ç å™¨åŸºæœ¬åŠŸèƒ½")
    print("=" * 60)
    
    # è®¾ç½®å‚æ•°
    hidden_size = 128
    n_layers = 2
    num_heads = 8
    k_neighbors = 6
    dropout = 0.1
    rbf_dim = 8
    cutoff = 8.0
    
    # åˆ›å»ºDSANç¼–ç å™¨
    try:
        encoder = DSANEncoder(
            hidden_size=hidden_size,
            n_layers=n_layers,
            num_heads=num_heads,
            k_neighbors=k_neighbors,
            dropout=dropout,
            use_geometry=True,
            rbf_dim=rbf_dim,
            cutoff=cutoff,
            memory_efficient=True  # å¯ç”¨æ˜¾å­˜ä¼˜åŒ–
        )
        print("âœ… DSANç¼–ç å™¨åˆ›å»ºæˆåŠŸ")
        print(f"   å‚æ•°æ•°é‡: {count_parameters(encoder) / 1e6:.2f}M")
    except Exception as e:
        print(f"âŒ DSANç¼–ç å™¨åˆ›å»ºå¤±è´¥: {e}")
        return False
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    encoder = encoder.to(device)
    
    batch_size = 2
    n_atoms_per_graph = 50
    n_blocks_per_graph = 10
    n_channel = 1
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    H = torch.randn(batch_size * n_atoms_per_graph, hidden_size, device=device)
    Z = torch.randn(batch_size * n_atoms_per_graph, n_channel, 3, device=device)
    
    # å—IDå’Œæ‰¹æ¬¡ID
    block_id = torch.repeat_interleave(torch.arange(batch_size * n_blocks_per_graph), 
                                       n_atoms_per_graph // n_blocks_per_graph).to(device)
    batch_id = torch.repeat_interleave(torch.arange(batch_size), n_atoms_per_graph).to(device)
    
    # ç®€å•çš„è¾¹ç´¢å¼•ï¼ˆå—é—´è¾¹ï¼‰
    n_edges = 20
    edges = torch.randint(0, batch_size * n_blocks_per_graph, (2, n_edges), device=device)
    
    print(f"æµ‹è¯•æ•°æ®å½¢çŠ¶:")
    print(f"   H: {H.shape}")
    print(f"   Z: {Z.shape}")
    print(f"   block_id: {block_id.shape}")
    print(f"   batch_id: {batch_id.shape}")
    print(f"   edges: {edges.shape}")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    try:
        with torch.no_grad():
            atom_features, block_repr, graph_repr, pred_Z = encoder(
                H, Z, block_id, batch_id, edges
            )
        
        print("âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"   atom_features: {atom_features.shape}")
        print(f"   block_repr: {block_repr.shape}")
        print(f"   graph_repr: {graph_repr.shape}")
        print(f"   pred_Z: {pred_Z.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_dsan_layer():
    """æµ‹è¯•å•ä¸ªDSANå±‚"""
    print("=" * 60)
    print("ğŸ§ª æµ‹è¯•å•ä¸ªDSANå±‚")
    print("=" * 60)
    
    # å‚æ•°
    hidden_size = 128
    num_heads = 8
    k_neighbors = 6
    
    try:
        layer = DSANLayer(
            hidden_size=hidden_size,
            num_heads=num_heads,
            k_neighbors=k_neighbors,
            memory_efficient=True
        )
        print("âœ… DSANå±‚åˆ›å»ºæˆåŠŸ")
        print(f"   å‚æ•°æ•°é‡: {count_parameters(layer) / 1e6:.3f}M")
    except Exception as e:
        print(f"âŒ DSANå±‚åˆ›å»ºå¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•æ•°æ®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    layer = layer.to(device)
    
    n_atoms = 100
    atom_features = torch.randn(n_atoms, hidden_size, device=device)
    atom_positions = torch.randn(n_atoms, 3, device=device)
    block_id = torch.randint(0, 20, (n_atoms,), device=device)
    inter_edges = torch.randint(0, 20, (2, 30), device=device)
    
    try:
        with torch.no_grad():
            updated_features = layer(atom_features, atom_positions, block_id, inter_edges)
        
        print("âœ… DSANå±‚å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"   è¾“å…¥ç‰¹å¾: {atom_features.shape}")
        print(f"   è¾“å‡ºç‰¹å¾: {updated_features.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ DSANå±‚å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_dsan_integration():
    """æµ‹è¯•DSANä¸è®­ç»ƒæ¡†æ¶çš„é›†æˆ"""
    print("=" * 60)
    print("ğŸ§ª æµ‹è¯•DSANä¸è®­ç»ƒæ¡†æ¶é›†æˆ")
    print("=" * 60)
    
    # æ¨¡æ‹Ÿè®­ç»ƒå‚æ•°
    class Args:
        task = 'PDBBind'  # æ·»åŠ å¿…éœ€çš„taskå‚æ•°
        noisy_sigma = 0.0  # æ·»åŠ å™ªå£°å‚æ•°
        model_type = 'DSAN'
        hidden_size = 128
        n_channel = 1
        n_rbf = 16
        cutoff = 8.0
        radial_size = 8
        k_neighbors = 6
        n_layers = 2
        n_head = 8
        atom_level = False
        hierarchical = False
        no_block_embedding = False
        pretrain_ckpt = None  # æ·»åŠ é¢„è®­ç»ƒæ£€æŸ¥ç‚¹å‚æ•°
    
    args = Args()
    
    try:
        model = create_model(args)
        print("âœ… DSANæ¨¡å‹é›†æˆåˆ›å»ºæˆåŠŸ")
        print(f"   æ¨¡å‹ç±»å‹: {type(model)}")
        print(f"   å‚æ•°æ•°é‡: {count_parameters(model) / 1e6:.2f}M")
        
        # æ£€æŸ¥ç¼–ç å™¨ç±»å‹
        if hasattr(model, 'encoder'):
            print(f"   ç¼–ç å™¨ç±»å‹: {type(model.encoder)}")
            print(f"   ç¼–ç å™¨å‚æ•°: {count_parameters(model.encoder) / 1e6:.2f}M")
        
        return True
        
    except Exception as e:
        print(f"âŒ DSANæ¨¡å‹é›†æˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def check_memory_usage():
    """æ£€æŸ¥æ˜¾å­˜ä½¿ç”¨æƒ…å†µ"""
    print("=" * 60)
    print("ğŸ’¾ æ˜¾å­˜ä½¿ç”¨æƒ…å†µ")
    print("=" * 60)
    
    if torch.cuda.is_available():
        print(f"GPUè®¾å¤‡: {torch.cuda.get_device_name()}")
        print(f"æ€»æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        print(f"å·²åˆ†é…æ˜¾å­˜: {torch.cuda.memory_allocated() / 1024**3:.2f} GB")
        print(f"å·²é¢„ç•™æ˜¾å­˜: {torch.cuda.memory_reserved() / 1024**3:.2f} GB")
        print(f"å¯ç”¨æ˜¾å­˜: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_reserved()) / 1024**3:.1f} GB")
    else:
        print("CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ DSANæ¨¡å‹å®Œæ•´æµ‹è¯•")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"GPUåç§°: {torch.cuda.get_device_name()}")
    
    # åˆå§‹æ˜¾å­˜æ£€æŸ¥
    check_memory_usage()
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        ("DSANå±‚æµ‹è¯•", test_dsan_layer),
        ("DSANç¼–ç å™¨æµ‹è¯•", test_dsan_encoder),
        ("DSANé›†æˆæµ‹è¯•", test_dsan_integration),
    ]
    
    results = []
    for test_name, test_func in tests:
        print(f"\nâ–¶ï¸ è¿è¡Œ {test_name}...")
        try:
            result = test_func()
            results.append((test_name, result))
            if result:
                print(f"âœ… {test_name} é€šè¿‡")
            else:
                print(f"âŒ {test_name} å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_name} å¼‚å¸¸: {e}")
            results.append((test_name, False))
        
        # æ¸…ç†æ˜¾å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
    
    # æœ€ç»ˆæ˜¾å­˜æ£€æŸ¥
    print("\n")
    check_memory_usage()
    
    # æ±‡æ€»ç»“æœ
    print("=" * 60)
    print("ğŸ“‹ æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    passed = 0
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"   {test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»è®¡: {passed}/{len(results)} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == len(results):
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼DSANæ¨¡å‹å‡†å¤‡å°±ç»ª")
        return 0
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é—®é¢˜")
        return 1

if __name__ == "__main__":
    exit(main())
