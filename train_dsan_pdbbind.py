#!/usr/bin/env python3
"""
è®­ç»ƒDSANæ¨¡å‹åœ¨PDBBind identity30æ•°æ®é›†ä¸Šï¼ˆæ˜¾å­˜ä¼˜åŒ–ç‰ˆï¼‰
"""

import subprocess
import sys
import os

def main():
    print("ğŸš€ å¯åŠ¨DSANæ¨¡å‹è®­ç»ƒï¼ˆæ˜¾å­˜ä¼˜åŒ–ç‰ˆï¼‰...")
    print("=" * 60)
    
    # æ£€æŸ¥GPUçŠ¶æ€
    print("GPUçŠ¶æ€æ£€æŸ¥:")
    import torch
    print(f"   CUDAå¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"   GPUæ•°é‡: {torch.cuda.device_count()}")
        print(f"   GPUåç§°: {torch.cuda.get_device_name(0)}")
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"   æ˜¾å­˜å¤§å°: {gpu_memory:.1f} GB")
        print(f"   å½“å‰æ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated() / 1024**3:.2f} GB")
        print(f"   æ˜¾å­˜åˆ©ç”¨ç‡: {torch.cuda.memory_allocated() / torch.cuda.get_device_properties(0).total_memory * 100:.1f}%")
    print("=" * 60)
    
    # æ„å»ºä¼˜åŒ–çš„è®­ç»ƒå‘½ä»¤
    cmd = [
        sys.executable, "train.py",
        "--train_set", "./datasets/PDBBind/processed/identity30/train.pkl",
        "--valid_set", "./datasets/PDBBind/processed/identity30/valid.pkl", 
        "--save_dir", "./datasets/PDBBind/processed/identity30/models/DSAN_memory_optimized",
        "--task", "PDBBind",
        "--lr", "0.001",
        "--final_lr", "0.0001", 
        "--max_epoch", "100",
        "--save_topk", "5",
        "--batch_size", "4",  # å¢åŠ åˆ°4æµ‹è¯•ä¿®å¤æ•ˆæœ
        "--valid_batch_size", "4",
        "--grad_clip", "1.0",
        "--warmup", "1000",
        "--shuffle",
        "--model_type", "DSAN",  # ä½¿ç”¨æ˜¾å­˜ä¼˜åŒ–çš„DSAN
        "--hidden_size", "128",
        "--n_layers", "3",  # ä¿æŒ3å±‚
        "--n_channel", "1", 
        "--n_rbf", "16",      # ä»32å‡å°‘åˆ°16ï¼Œå‡å°‘è¾¹ç‰¹å¾ç»´åº¦
        "--cutoff", "8.0",    # ä»10.0å‡å°‘åˆ°8.0ï¼Œå‡å°‘è¾¹æ•°é‡
        "--n_head", "8",      # ä¿æŒ8ä¸ªæ³¨æ„åŠ›å¤´
        "--radial_size", "8", # ä»16å‡å°‘åˆ°8ï¼Œå‡å°‘å‡ ä½•ç‰¹å¾ç»´åº¦
        "--k_neighbors", "6", # ä»9å‡å°‘åˆ°6ï¼Œæ˜¾è‘—å‡å°‘è¾¹æ•°é‡ï¼ˆå…³é”®ä¼˜åŒ–ï¼‰
        "--seed", "2024",
        "--gpus", "0"
    ]
    
    print("DSANè®­ç»ƒé…ç½®ï¼ˆæ˜¾å­˜ä¼˜åŒ–ï¼‰:")
    print(f"   æ‰¹æ¬¡å¤§å°: 4 (æµ‹è¯•ä¿®å¤æ•ˆæœ)")
    print(f"   RBFç»´åº¦: 16 (å‡å°‘è¾¹ç‰¹å¾)")
    print(f"   Cutoffè·ç¦»: 8.0 (å‡å°‘è¾¹æ•°é‡)")
    print(f"   å‡ ä½•ç‰¹å¾ç»´åº¦: 8 (å‡å°‘è®¡ç®—)")
    print(f"   Kè¿‘é‚»æ•°: 6 (å…³é”®ï¼šå‡å°‘ESAå¤æ‚åº¦)")
    print(f"   æ³¨æ„åŠ›å¤´æ•°: 8")
    print(f"   å±‚æ•°: 3")
    print(f"   éšè—å±‚å¤§å°: 128")
    print("=" * 60)
    
    print("æ˜¾å­˜ä¼˜åŒ–ç‰¹æ€§:")
    print("   âœ… æ‰¹é‡å—å¤„ç†ï¼ˆBatch Block Processingï¼‰")
    print("   âœ… å‘é‡åŒ–PMAï¼ˆVectorized PMAï¼‰")
    print("   âœ… æ˜¾å­˜æ¸…ç†ï¼ˆMemory Cache Clearingï¼‰")
    print("   âœ… åˆ†å—å‡ ä½•è®¡ç®—ï¼ˆChunked Geometry Computingï¼‰")
    print("   âš ï¸  æ¢¯åº¦æ£€æŸ¥ç‚¹å·²æš‚æ—¶ç¦ç”¨ï¼ˆé¿å…åŠ¨æ€å½¢çŠ¶å†²çªï¼‰")
    print("=" * 60)
    
    # æ‰§è¡Œè®­ç»ƒ
    print("ğŸ¯ å¼€å§‹è®­ç»ƒ... (Ctrl+C ä¸­æ–­)")
    import time
    start_time = time.time()
    
    try:
        result = subprocess.run(cmd, check=True)
        
        end_time = time.time()
        training_time = (end_time - start_time) / 3600  # hours
        
        print("âœ… è®­ç»ƒå®Œæˆ!")
        print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: ./datasets/PDBBind/processed/identity30/models/DSAN_memory_optimized")
        print(f"è®­ç»ƒç”¨æ—¶: {training_time:.2f} å°æ—¶")
        
        return 0
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        print("å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("   1. æ£€æŸ¥æ•°æ®é›†è·¯å¾„æ˜¯å¦æ­£ç¡®")
        print("   2. è¿›ä¸€æ­¥å‡å°‘batch_size")
        print("   3. å‡å°‘k_neighborsæˆ–cutoff")
        print("   4. æ£€æŸ¥GPUæ˜¾å­˜æ˜¯å¦è¶³å¤Ÿ")
        return 1
    except KeyboardInterrupt:
        print("â›” è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
        return 1
    finally:
        # æ¸…ç†GPUæ˜¾å­˜
        if 'torch' in sys.modules:
            torch.cuda.empty_cache()
            final_memory = torch.cuda.memory_allocated() / 1024**3
            print(f"æœ€ç»ˆæ˜¾å­˜å ç”¨: {final_memory:.2f} GB")
        print("=" * 60)
        print("è®­ç»ƒç»“æŸ")

if __name__ == "__main__":
    exit(main())
