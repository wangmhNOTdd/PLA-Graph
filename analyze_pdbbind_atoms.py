#!/usr/bin/env python3
"""
ç»Ÿè®¡PDBbindæ•°æ®é›†ä¸­å¤åˆç‰©çš„åŽŸå­ä¸ªæ•°
åŒ…æ‹¬æžç«¯å€¼ã€å¹³å‡å€¼ã€ä¸­ä½æ•°ç­‰ç»Ÿè®¡ä¿¡æ¯
"""

import pickle
import numpy as np
from collections import defaultdict
import os
import sys

def load_dataset(pkl_path):
    """åŠ è½½pickleæ•°æ®é›†"""
    print(f"æ­£åœ¨åŠ è½½æ•°æ®é›†: {pkl_path}")
    with open(pkl_path, 'rb') as f:
        data = pickle.load(f)
    print(f"æ•°æ®é›†å¤§å°: {len(data)} ä¸ªå¤åˆç‰©")
    return data

def analyze_atom_counts(data, dataset_name):
    """åˆ†æžåŽŸå­ä¸ªæ•°ç»Ÿè®¡"""
    print(f"\n=== {dataset_name} æ•°æ®é›†åŽŸå­ä¸ªæ•°ç»Ÿè®¡ ===")
    
    atom_counts = []
    block_counts = []
    segment_info = defaultdict(list)
    
    for i, item in enumerate(data):
        if isinstance(item, dict) and 'data' in item:
            # PDBBindBenchmark æ ¼å¼
            sample_data = item['data']
        else:
            # ç›´æŽ¥çš„æ•°æ®æ ¼å¼
            sample_data = item
            
        # ç»Ÿè®¡åŽŸå­ä¸ªæ•°
        if 'A' in sample_data:
            n_atoms = len(sample_data['A'])
            atom_counts.append(n_atoms)
        
        # ç»Ÿè®¡å—ä¸ªæ•°  
        if 'B' in sample_data:
            n_blocks = len(sample_data['B'])
            block_counts.append(n_blocks)
            
        # ç»Ÿè®¡æ¯ä¸ªsegmentçš„ä¿¡æ¯
        if 'segment_ids' in sample_data:
            segments = sample_data['segment_ids']
            unique_segments = set(segments)
            for seg_id in unique_segments:
                seg_blocks = [i for i, s in enumerate(segments) if s == seg_id]
                segment_info[seg_id].append(len(seg_blocks))
    
    atom_counts = np.array(atom_counts)
    block_counts = np.array(block_counts)
    
    # åŸºæœ¬ç»Ÿè®¡
    print(f"\nðŸ“Š åŽŸå­ä¸ªæ•°ç»Ÿè®¡:")
    print(f"   æ ·æœ¬æ•°é‡: {len(atom_counts)}")
    print(f"   æœ€å°å€¼: {np.min(atom_counts)} ä¸ªåŽŸå­")
    print(f"   æœ€å¤§å€¼: {np.max(atom_counts)} ä¸ªåŽŸå­") 
    print(f"   å¹³å‡å€¼: {np.mean(atom_counts):.2f} ä¸ªåŽŸå­")
    print(f"   ä¸­ä½æ•°: {np.median(atom_counts):.2f} ä¸ªåŽŸå­")
    print(f"   æ ‡å‡†å·®: {np.std(atom_counts):.2f} ä¸ªåŽŸå­")
    
    # ç™¾åˆ†ä½æ•°
    percentiles = [5, 10, 25, 75, 90, 95]
    print(f"\nðŸ“ˆ åŽŸå­ä¸ªæ•°ç™¾åˆ†ä½æ•°:")
    for p in percentiles:
        val = np.percentile(atom_counts, p)
        print(f"   {p}%: {val:.0f} ä¸ªåŽŸå­")
    
    # å—ç»Ÿè®¡
    if len(block_counts) > 0:
        print(f"\nðŸ§± å—ä¸ªæ•°ç»Ÿè®¡:")
        print(f"   æœ€å°å€¼: {np.min(block_counts)} ä¸ªå—")
        print(f"   æœ€å¤§å€¼: {np.max(block_counts)} ä¸ªå—")
        print(f"   å¹³å‡å€¼: {np.mean(block_counts):.2f} ä¸ªå—")
        print(f"   ä¸­ä½æ•°: {np.median(block_counts):.2f} ä¸ªå—")
    
    # Segmentåˆ†æž
    if segment_info:
        print(f"\nðŸ—ï¸ Segmentåˆ†æž:")
        for seg_id, block_counts_per_seg in segment_info.items():
            if len(block_counts_per_seg) > 0:
                avg_blocks = np.mean(block_counts_per_seg)
                print(f"   Segment {seg_id}: å¹³å‡ {avg_blocks:.2f} ä¸ªå—")
    
    # åˆ†å¸ƒåŒºé—´ç»Ÿè®¡
    print(f"\nðŸ“ˆ åŽŸå­ä¸ªæ•°åˆ†å¸ƒ:")
    ranges = [(0, 500), (500, 1000), (1000, 2000), (2000, 5000), (5000, float('inf'))]
    for low, high in ranges:
        if high == float('inf'):
            count = np.sum(atom_counts >= low)
            print(f"   {low}+ ä¸ªåŽŸå­: {count} ä¸ªå¤åˆç‰© ({count/len(atom_counts)*100:.1f}%)")
        else:
            count = np.sum((atom_counts >= low) & (atom_counts < high))
            print(f"   {low}-{high} ä¸ªåŽŸå­: {count} ä¸ªå¤åˆç‰© ({count/len(atom_counts)*100:.1f}%)")
    
    return atom_counts, block_counts

def main():
    """ä¸»å‡½æ•°"""
    print("ðŸ§¬ PDBbindæ•°æ®é›†åŽŸå­ä¸ªæ•°ç»Ÿè®¡åˆ†æž")
    print("=" * 60)
    
    # æ•°æ®é›†è·¯å¾„
    datasets = {
        'Train': './datasets/PDBBind/processed/identity30/train.pkl',
        'Valid': './datasets/PDBBind/processed/identity30/valid.pkl', 
        'Test': './datasets/PDBBind/processed/identity30/test.pkl'
    }
    
    atom_counts_dict = {}
    
    # åˆ†æžæ¯ä¸ªæ•°æ®é›†
    for name, path in datasets.items():
        if os.path.exists(path):
            try:
                data = load_dataset(path)
                atom_counts, block_counts = analyze_atom_counts(data, name)
                atom_counts_dict[name] = atom_counts
            except Exception as e:
                print(f"âŒ å¤„ç†{name}æ•°æ®é›†æ—¶å‡ºé”™: {e}")
        else:
            print(f"âš ï¸  æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {path}")
    
    # åˆå¹¶ç»Ÿè®¡
    if atom_counts_dict:
        print(f"\n=== åˆå¹¶ç»Ÿè®¡ ===")
        all_atom_counts = np.concatenate(list(atom_counts_dict.values()))
        print(f"ðŸ“Š æ‰€æœ‰æ•°æ®é›†åˆå¹¶ç»Ÿè®¡:")
        print(f"   æ€»æ ·æœ¬æ•°: {len(all_atom_counts)}")
        print(f"   æœ€å°å€¼: {np.min(all_atom_counts)} ä¸ªåŽŸå­")
        print(f"   æœ€å¤§å€¼: {np.max(all_atom_counts)} ä¸ªåŽŸå­")
        print(f"   å¹³å‡å€¼: {np.mean(all_atom_counts):.2f} ä¸ªåŽŸå­")
        print(f"   ä¸­ä½æ•°: {np.median(all_atom_counts):.2f} ä¸ªåŽŸå­")
        print(f"   æ ‡å‡†å·®: {np.std(all_atom_counts):.2f} ä¸ªåŽŸå­")
        
        # å¯»æ‰¾æžç«¯å€¼æ ·æœ¬
        print(f"\nðŸ” æžç«¯å€¼æ ·æœ¬:")
        min_idx = np.argmin(all_atom_counts)
        max_idx = np.argmax(all_atom_counts)
        print(f"   æœ€å°åŽŸå­æ•°æ ·æœ¬: {np.min(all_atom_counts)} ä¸ªåŽŸå­")
        print(f"   æœ€å¤§åŽŸå­æ•°æ ·æœ¬: {np.max(all_atom_counts)} ä¸ªåŽŸå­")
        
        # ç»˜åˆ¶åˆ†å¸ƒå›¾ï¼ˆéœ€è¦matplotlibï¼‰
        # try:
        #     plot_distribution(atom_counts_dict, './analysis_results')
        # except Exception as e:
        #     print(f"âš ï¸  ç»˜å›¾æ—¶å‡ºé”™: {e}")
        
        print(f"\nðŸ’¾ ç»Ÿè®¡ç»“æžœå·²ä¿å­˜åˆ°ç»ˆç«¯è¾“å‡º")
    
    print("\nâœ… åˆ†æžå®Œæˆ!")

if __name__ == "__main__":
    main()
